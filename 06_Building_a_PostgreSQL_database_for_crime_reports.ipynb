{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "06-Building-a-PostgreSQL-database-for-crime-reports.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lis-r-barreto/Data-Engineering/blob/main/06_Building_a_PostgreSQL_database_for_crime_reports.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "M3SxabCdSP1E"
      },
      "source": [
        "# Building a PostgreSQL database for crime reports\n",
        "\n",
        "In this brief project we will cover the following aspects of managing databases with Postgres:\n",
        "\n",
        "- How to create a database and manage database roles.\n",
        "- How to create database schemas and tables with the proper datatypes.\n",
        "- How to load data from CSV files into database tables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11XnwXm0SP1J"
      },
      "source": [
        "We will put all this together to build a database for storing data related with crimes that occurred in Boston. This dataset is available in the file `boston.csv`.\n",
        "Here we can see the first few rows of the file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ac6Y_YHSP1N"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import psycopg2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw-_PjNiSP1Q",
        "outputId": "0873ad40-4f19-4e08-c0bd-eeb9f8b23b34"
      },
      "source": [
        "data = pd.read_csv('boston.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_number</th>\n",
              "      <th>offense_code</th>\n",
              "      <th>description</th>\n",
              "      <th>date</th>\n",
              "      <th>day_of_the_week</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>619</td>\n",
              "      <td>LARCENY ALL OTHERS</td>\n",
              "      <td>2018-09-02</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>42.357791</td>\n",
              "      <td>-71.139371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1402</td>\n",
              "      <td>VANDALISM</td>\n",
              "      <td>2018-08-21</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>42.306821</td>\n",
              "      <td>-71.060300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3410</td>\n",
              "      <td>TOWED MOTOR VEHICLE</td>\n",
              "      <td>2018-09-03</td>\n",
              "      <td>Monday</td>\n",
              "      <td>42.346589</td>\n",
              "      <td>-71.072429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>3114</td>\n",
              "      <td>INVESTIGATE PROPERTY</td>\n",
              "      <td>2018-09-03</td>\n",
              "      <td>Monday</td>\n",
              "      <td>42.334182</td>\n",
              "      <td>-71.078664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3114</td>\n",
              "      <td>INVESTIGATE PROPERTY</td>\n",
              "      <td>2018-09-03</td>\n",
              "      <td>Monday</td>\n",
              "      <td>42.275365</td>\n",
              "      <td>-71.090361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   incident_number  offense_code           description        date  \\\n",
              "0                1           619    LARCENY ALL OTHERS  2018-09-02   \n",
              "1                2          1402             VANDALISM  2018-08-21   \n",
              "2                3          3410   TOWED MOTOR VEHICLE  2018-09-03   \n",
              "3                4          3114  INVESTIGATE PROPERTY  2018-09-03   \n",
              "4                5          3114  INVESTIGATE PROPERTY  2018-09-03   \n",
              "\n",
              "  day_of_the_week        lat       long  \n",
              "0          Sunday  42.357791 -71.139371  \n",
              "1         Tuesday  42.306821 -71.060300  \n",
              "2          Monday  42.346589 -71.072429  \n",
              "3          Monday  42.334182 -71.078664  \n",
              "4          Monday  42.275365 -71.090361  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE9Yf8j3SP1S"
      },
      "source": [
        "As a description of the file:\n",
        "\n",
        "- The first column represents the identifier of the crime. \n",
        "- The second contains a numeric identifier code for the committed crime. \n",
        "- The third represents a description of the crime. \n",
        "- The next two rows contain the date on which the crime happened and the corresponding day of the week. \n",
        "- The last two columns represent the location of the crime with a latitude and longitude coordinates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HwAq8r-SP1V"
      },
      "source": [
        "## Road map\n",
        "\n",
        "The goal of the project is to create a database named `crimes_db` with a table – `boston_crimes` – with appropriate datatypes for storing the data from the `boston.csv` file. \n",
        "\n",
        "We will be creating the table inside a schema named `crimes`. \n",
        "We will also create the `readonly` and `readwrite` groups with the appropriate privileges. \n",
        "\n",
        "Finally, we will also create one user for each of these groups.\n",
        "\n",
        "## Create `crimes_db` database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO90AIk6SP1X"
      },
      "source": [
        "conn = psycopg2.connect(dbname='postgres', user='postgres')\n",
        "cur = conn.cursor()\n",
        "# set autocommit to True bacause this is required for creating databases\n",
        "conn.autocommit = True\n",
        "cur.execute(\"CREATE DATABASE crimes_db;\")\n",
        "conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELe4oCKpSP1Z"
      },
      "source": [
        "# Connect to the new database\n",
        "conn = psycopg2.connect(dbname='crimes_db', user='postgres')\n",
        "conn.autocommit = True\n",
        "cur = conn.cursor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg17l4L4SP1d"
      },
      "source": [
        "# Create the crimes schema\n",
        "cur.execute(\"CREATE SCHEMA crimes;\")\n",
        "conn.commit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgnRdMSLSP1h"
      },
      "source": [
        "## Obtaining the Column Names and Sample\n",
        "Here we read the header row and assign it to a variable named `col_headers` and read the first data row and assign it to a variable named `first_row`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a478MaQhSP1j"
      },
      "source": [
        "with open('boston.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    col_headers = next(reader)\n",
        "    first_row = next(reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUoaaSE0SP1l",
        "outputId": "e22e7702-8200-41d4-b68e-2f93620ed328"
      },
      "source": [
        "# Check the column names and sample\n",
        "print(col_headers)\n",
        "print(first_row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
            "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNYj_FDHSP1n"
      },
      "source": [
        "## Creating a function for analyzing column values¶\n",
        "\n",
        "Before we create a table for storing the crime data, we need to identify the proper datatypes for the columns. To help us with that, let's create a function `get_col_set()` that given the name of a CSV file and a column index (starting at 0) computes a Python `Set` with all distinct values contained in that column.\n",
        "\n",
        "This function will be useful for two reasons:\n",
        "\n",
        "- Checking whether an `enumerated` datatype might be a good choice for representing a column.\n",
        "- Computing the maximum length of any text-like column to select appropriate sizes for `VARCHAR` columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPh_4-EhSP1o"
      },
      "source": [
        "# Create the function\n",
        "def get_col_set(csv_filename, col_index):\n",
        "    \n",
        "    \"\"\"Output: a Python set that contains all distinct values from the col_index in csv_filename.\"\"\"\n",
        "    \n",
        "    distinct_values = set()\n",
        "    with open(csv_filename) as file:\n",
        "        reader = csv.reader(file)\n",
        "        next(reader) # Skip headers row\n",
        "        for row in reader:\n",
        "            distinct_values.add(row[col_index])\n",
        "    return distinct_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjag8YLHSP1p"
      },
      "source": [
        "- Let's compute the number of different values in each column of the boston.csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svDJfrVsSP1q",
        "outputId": "8d083a2c-b4f4-49eb-ea9f-8a528cc1ce72"
      },
      "source": [
        "for col_index in range(7):\n",
        "    number_distinct_values = len(get_col_set('boston.csv', col_index))\n",
        "    print(\"{}: {}\".format(col_headers[col_index], number_distinct_values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "incident_number: 298329\n",
            "offense_code: 219\n",
            "description: 239\n",
            "date: 1177\n",
            "day_of_the_week: 7\n",
            "lat: 18177\n",
            "long: 18177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeW5BX56SP1r"
      },
      "source": [
        "## Analyzing the maximum length of the text columns¶\n",
        "\n",
        "In order to pick the right datatypes for our table we need to know the maximum amount of characters in a single entry for each text column.\n",
        "\n",
        "The `day_of_the_week` column contains only 7 values, one for each day, which makes it a good candidate for an enumerated datatype. \n",
        "We can tell that the longest of them is `Wednesday` without needing any computation.\n",
        "\n",
        "For the `description` column we will reuse the function from the last step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2c0_mAcSP1t",
        "outputId": "2a629836-a6e1-4fcd-cdf4-aedc4b5c96f8"
      },
      "source": [
        "# Check column index numbers\n",
        "print(col_headers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm-M-L_kSP1u",
        "outputId": "4fb7cf97-a84b-484e-aab8-99be487e86ec"
      },
      "source": [
        "# day_of_the_week column is at index 4\n",
        "print(get_col_set('boston.csv', 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Tuesday', 'Monday', 'Friday', 'Sunday', 'Wednesday', 'Saturday', 'Thursday'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1NfgVqnoSP1v",
        "outputId": "ab37aa0a-fb28-4d93-dff6-bc810b26edb9"
      },
      "source": [
        "# description column is at index 2\n",
        "description_column = get_col_set('boston.csv', 2)\n",
        "max_value = 0\n",
        "for value in description_column:\n",
        "    max_value = max(len(value), max_value)\n",
        "print('Maximum amount of characters for a single value:', max_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum amount of characters for a single value: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhThQpA8SP1w"
      },
      "source": [
        "## Creating the table\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cpyAfPWSP1w",
        "outputId": "7e23c0e6-b849-4645-cb47-093ebb81c004"
      },
      "source": [
        "print(col_headers)\n",
        "print(first_row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
            "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppx4_hzzSP1y"
      },
      "source": [
        "We will use the same names for the column headers.\n",
        "\n",
        "The amount of distinct values for each column was:\n",
        "\n",
        "    incident_number 298329\n",
        "    offense_code       219\n",
        "    description        239\n",
        "    date              1177\n",
        "    day_of_the_week      7\n",
        "    lat              18177\n",
        "    long             18177\n",
        "    \n",
        "From the result of printing `first_row` we see that the different types of data that we have are:\n",
        "\n",
        "    integer numbers\n",
        "    integer numbers\n",
        "    string\n",
        "    date\n",
        "    string\n",
        "    decimal number\n",
        "    decimal number\n",
        "    \n",
        "The `day_of_the_week` column has a small range of values so we will create an enumerated datatype named `WEEKDAY_ENUM`. The `offense_code` column would also be a good candidate since there is probably a limited set of possible offense codes.\n",
        "\n",
        "For the `incident_number` column we have decided to use the type `INTEGER` and set it as the `PRIMARY KEY`. The same datatype will be used to represent the `offense_code` column.\n",
        "\n",
        "We saw that the `description` column has size at most 59. To be on the safe side we will limit the size of the description to 100 and use the `VARCHAR(100)` datatype.\n",
        "\n",
        "Finally, the `lat` and `long` columns seem to need to hold quite a lot of precision so we will use the `DECIMAL` type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_y7fiRzSP1z"
      },
      "source": [
        "# Create enumerated datatype for day_of_the_week\n",
        "cur.execute(\"\"\"CREATE TYPE weekday_enum AS ENUM (\n",
        "            'Saturday', 'Thursday', 'Sunday', 'Wednesday', 'Monday', 'Friday', 'Tuesday');\n",
        "\"\"\")\n",
        "\n",
        "# Create table\n",
        "cur.execute(\"\"\"\n",
        "    CREATE TABLE crimes.boston_crimes (\n",
        "        incident_number INTEGER PRIMARY KEY,\n",
        "        offense_code INTEGER,\n",
        "        description VARCHAR(100),\n",
        "        date DATE,\n",
        "        day_of_the_week WEEKDAY_ENUM,\n",
        "        lat DECIMAL(11,8),\n",
        "        long DECIMAL(11,8)\n",
        "    );\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG1v_XDCSP10"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "In order to move the data from our file, `boston.csv`, to our newly created table we will use the `cursor.copy_expert` method.\n",
        "\n",
        "There are many ways to load CSV data into a Postgres table. We could read the file and execute queries to add the lines one by one to our table. But the `cursor.copy_expert` method is more robust and much faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ARMlYphSP10"
      },
      "source": [
        "# Load the data from boston.csv into the table boston_crimes in the crimes schema\n",
        "with open('boston.csv') as file:\n",
        "    cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER;\", file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHNY2bhUSP11",
        "outputId": "8d814d93-2c18-4e85-86ef-ab0ecfa336e3"
      },
      "source": [
        "cur.execute(\"SELECT * FROM crimes.boston_crimes\")\n",
        "# print the number of rows to ensure that they were loaded\n",
        "print(len(cur.fetchall()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "298329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcoBna2BSP11"
      },
      "source": [
        "## Revoke public privileges¶\n",
        "\n",
        "We will move on to creating our `readonly` and `readwrite` groups. Each group will have access to specific privileges according to their function.\n",
        "\n",
        "By following the least privilege principle, the first step is to make sure that there are no privileges inherited from the `public group` and on the `public schema`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYd9S7C6SP12"
      },
      "source": [
        "# Revoke privileges from public schema\n",
        "cur.execute(\"REVOKE ALL ON SCHEMA public FROM public;\")\n",
        "# Revoke privileges from public group\n",
        "cur.execute(\"REVOKE ALL ON DATABASE crimes_db FROM public;\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVwOxG3ZSP13"
      },
      "source": [
        "## Creating the `readonly` group¶\n",
        "\n",
        "We create a `readonly` group with `NOLOGIN` because it is a group and not a user. We grant the group the ability to `CONNECT` to the `crimes_db` and the ability to use the `crimes` schema.\n",
        "\n",
        "This group will only be able to use the `SELECT` command when quering.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hSHsGY9SP13"
      },
      "source": [
        "cur.execute(\"CREATE GROUP readonly NOLOGIN;\")\n",
        "cur.execute(\"GRANT CONNECT ON DATABASE crimes_db TO readonly;\")\n",
        "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readonly;\")\n",
        "cur.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly;\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg41vwNESP14"
      },
      "source": [
        "## Creating the `readwrite` group¶\n",
        "\n",
        "We create a `readwrite` group with `NOLOGIN` because it is a group and not a user. We grant the group the ability to `CONNECT` to the `crimes_db` and the ability to use the `crimes` schema.\n",
        "\n",
        "This group will have the SELECT, INSERT, UPDATE and DELETE priviliges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8N1aCniSP15"
      },
      "source": [
        "cur.execute(\"CREATE GROUP readwrite NOLOGIN;\")\n",
        "cur.execute(\"GRANT CONNECT ON DATABASE crimes_db TO readwrite;\")\n",
        "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readwrite;\")\n",
        "cur.execute(\"GRANT SELECT, INSERT, DELETE, UPDATE ON ALL TABLES IN SCHEMA crimes TO readwrite;\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQYFy8s9SP16"
      },
      "source": [
        "## Creating one user for each group¶\n",
        "\n",
        "The last big step on this project will be to create one user in each group. We will need to create each user and then assign them to each group. \n",
        "\n",
        "- We create a user named `data_analyst` with password `secret1` in the `readonly` group.\n",
        "\n",
        "- We create a user named `data_scientist` with password `secret2` in the `readwrite` group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH540lQeSP17"
      },
      "source": [
        "# Create user and add it to readonly group\n",
        "cur.execute(\"CREATE USER data_analyst WITH PASSWORD 'secret1';\")\n",
        "cur.execute(\"GRANT readonly TO data_analyst;\")\n",
        "\n",
        "# Create user and add it to readwrite group\n",
        "cur.execute(\"CREATE USER data_scientist WITH PASSWORD 'secret2';\")\n",
        "cur.execute(\"GRANT readwrite TO data_scientist;\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnFYGz4KSP17"
      },
      "source": [
        "## Test the database setup¶\n",
        "\n",
        "It is a good practice to test that everything is configured as expected when we finish setting up the database.\n",
        "To wrap up this project we will test the database setup using SQL queries to check whether the objects have been created and that users and groups have the right privileges.\n",
        "\n",
        "This requires us to know the Postgres internal tables. We can query the `pg_roles` table to inspect privileges related to the database and the `information_schema.table_privileges` table to inspect table privileges.\n",
        "\n",
        "In the `pg_roles` table we will check database related privileges. We will look at the following columns:\n",
        "\n",
        "- `rolname`: The name of the user / group that the privilege refers to.\n",
        "- `rolsuper`: Whether this user / group is a super user. It should be set to False on every user / group that we have created.\n",
        "- `rolcreaterole`: Whether user / group can create users, groups or roles. It should be False on every user / group that we have created.\n",
        "- `rolcreatedb`: Whether user / group can create databases. It should be False on every user / group that we have created.\n",
        "- `rolcanlogin`: Whether user / group can login. It should be True on the users and False on the groups that we have created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx6QCpTVSP18",
        "outputId": "0591398a-fe51-4f1a-a48c-34e80e37d7b4"
      },
      "source": [
        "# Close the old connection to test with a brand new connection\n",
        "conn.close()\n",
        "\n",
        "conn = psycopg2.connect(dbname=\"crimes_db\", user=\"postgres\")\n",
        "cur = conn.cursor()\n",
        "# Check users and groups\n",
        "cur.execute(\"\"\"\n",
        "    SELECT rolname, rolsuper, rolcreaterole, rolcreatedb, rolcanlogin FROM pg_roles\n",
        "    WHERE rolname IN ('readonly', 'readwrite', 'data_analyst', 'data_scientist');\n",
        "\"\"\")\n",
        "print('USERS AND GROUPS:')\n",
        "for user in cur:\n",
        "    print(user)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USERS AND GROUPS:\n",
            "('readonly', False, False, False, False)\n",
            "('readwrite', False, False, False, False)\n",
            "('data_analyst', False, False, False, True)\n",
            "('data_scientist', False, False, False, True)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDEmo7GVSP19"
      },
      "source": [
        "In the `information_schema.table_privileges` we will check privileges related to SQL queries on tables. We will list the privileges of each group that we have created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QDPjFRHSP1-",
        "outputId": "9ceb7165-3620-4215-827b-868c4c584bdf"
      },
      "source": [
        "# Check privileges\n",
        "cur.execute(\"\"\"\n",
        "    SELECT grantee, privilege_type\n",
        "    FROM information_schema.table_privileges\n",
        "    WHERE grantee IN ('readonly', 'readwrite');\n",
        "\"\"\")\n",
        "print('PRIVILEGES:')\n",
        "for user in cur:\n",
        "    print(user)\n",
        "conn.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PRIVILEGES:\n",
            "('readonly', 'SELECT')\n",
            "('readwrite', 'INSERT')\n",
            "('readwrite', 'SELECT')\n",
            "('readwrite', 'UPDATE')\n",
            "('readwrite', 'DELETE')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_1mhCFSP1-"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this project went through the basics of creating a database in PostgreSQL from a csv file.\n",
        "\n",
        "As a summarization, we:\n",
        "- Created our database\n",
        "- Explored the data to shape our first table\n",
        "- Created our table\n",
        "- Loaded the data from the csv file to our database\n",
        "- Created groups with customized privileges\n",
        "- Created users inside these groups\n",
        "\n",
        "This is of course just a way to kickstart our database which now has a lot of room for growing. More tables can be added and linked together. More users and group can be created. Much more data can be stored. \n",
        "\n",
        "And all these improvements will come with more challenges regarding keeping our database safe and organized. We will leave this for a future project.\n",
        "\n",
        "## Thank you for reading!\n",
        "\n"
      ]
    }
  ]
}