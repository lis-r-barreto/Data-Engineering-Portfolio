{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "02-Exploring-Hacker-News-Posts.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lis-r-barreto/Data-Engineering/blob/main/02_Exploring_Hacker_News_Posts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzsKWAjOQe5Y"
      },
      "source": [
        "# Exploring Hacker News Posts\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Hacker News is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
        "\n",
        "We're specifically interested in posts whose titles begin with either Ask HN or Show HN. Users submit Ask HN posts to ask the Hacker News community a specific question. Below is an example:\n",
        "\n",
        "*Ask HN: How to improve my personal website?*\n",
        "\n",
        "Likewise, users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting. Below is an example:\n",
        "\n",
        "*Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform'*\n",
        "\n",
        "We'll compare these two types of posts to determine the following:\n",
        "- Do Ask HN or Show HN receive more comments on average?\n",
        "- Do posts created at a certain time receive more comments on average?\n",
        "\n",
        "## Opening and Exploring the Data\n",
        "\n",
        "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
        "\n",
        "Below are descriptions of the columns:\n",
        "- id: The unique identifier from Hacker News for the post\n",
        "- title: The title of the post\n",
        "- url: The URL that the posts links to, if the post has a URL\n",
        "- num_points: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
        "- num_comments: The number of comments that were made on the post\n",
        "- author: The username of the person who submitted the post\n",
        "- created_at: The date and time at which the post was submitted\n",
        "\n",
        "\n",
        "Let's start by importing the libraries we need and reading the data set into a list of lists and explore first 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je2e1gI_Qe5h",
        "outputId": "3b954530-6ec6-46ed-9c71-075e35a06a2f"
      },
      "source": [
        "from csv import reader\n",
        "\n",
        "opened_file = open ('hacker_news.csv',encoding = 'utf8')\n",
        "read_file = reader (opened_file)\n",
        "hn = list (read_file)\n",
        "\n",
        "for row in hn[:5]:\n",
        "    print (row)\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
            "\n",
            "\n",
            "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
            "\n",
            "\n",
            "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
            "\n",
            "\n",
            "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
            "\n",
            "\n",
            "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sJH-DnPQe5m"
      },
      "source": [
        "Notice that the first list in the inner lists contains the column headers, and the lists after contain the data for one row. In order to analyze our data, we need to first remove the row containing the column headers. Let's remove that first row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COKia5fSQe5p",
        "outputId": "00362aa8-8178-41a1-8702-f5094e0de1f0"
      },
      "source": [
        "headers = hn[0]  #Do not run this cell more than once\n",
        "hn = hn[1:]\n",
        "\n",
        "print (headers)\n",
        "print('\\n')\n",
        "for row in hn[:5]:\n",
        "    print (row)\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
            "\n",
            "\n",
            "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
            "\n",
            "\n",
            "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
            "\n",
            "\n",
            "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
            "\n",
            "\n",
            "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
            "\n",
            "\n",
            "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELtv6Iu0Qe5r"
      },
      "source": [
        "Now that we've removed the headers from hn, we're ready to filter our data. Since we're only concerned with post titles beginning with **Ask HN** or **Show HN**, we'll create new lists of lists containing just the data for those titles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDN3EWw3Qe5t"
      },
      "source": [
        "## Sorting the Data\n",
        "\n",
        "To find the posts that begin with either Ask HN or Show HN (and case variations) , we'll use the string method startswith and check the data by printing five rows of each list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzOCBf8VQe5x",
        "outputId": "5adadb83-18ab-4f68-a77b-ba3ab8ab04bc"
      },
      "source": [
        "ask_posts = []\n",
        "show_posts = []\n",
        "other_posts = []\n",
        "\n",
        "for row in hn:\n",
        "    title = row[1]\n",
        "    title_lower = title.lower()\n",
        "    \n",
        "    if title_lower.startswith('ask hn'):\n",
        "        ask_posts.append(row)\n",
        "    \n",
        "    elif title_lower.startswith('show hn'):\n",
        "        show_posts.append(row)\n",
        "        \n",
        "    else:\n",
        "        other_posts.append(row)\n",
        "        \n",
        "for row in ask_posts[:5]:\n",
        "    print (row)\n",
        "    print('\\n')\n",
        "print('\\n')\n",
        "for row in show_posts[:5]:\n",
        "    print (row)\n",
        "    print('\\n')\n",
        "print('\\n')\n",
        "for row in other_posts[:5]:\n",
        "    print (row)\n",
        "    print('\\n')\n",
        "print('Number of Ask HN posts:',len(ask_posts))\n",
        "print('Number of Show HN posts:',len(show_posts))\n",
        "print('Number of Other posts:',len(other_posts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
            "\n",
            "\n",
            "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
            "\n",
            "\n",
            "['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']\n",
            "\n",
            "\n",
            "['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48']\n",
            "\n",
            "\n",
            "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
            "\n",
            "\n",
            "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
            "\n",
            "\n",
            "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
            "\n",
            "\n",
            "['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17']\n",
            "\n",
            "\n",
            "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
            "\n",
            "\n",
            "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
            "\n",
            "\n",
            "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
            "\n",
            "\n",
            "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
            "\n",
            "\n",
            "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
            "\n",
            "\n",
            "Number of Ask HN posts: 9139\n",
            "Number of Show HN posts: 10158\n",
            "Number of Other posts: 273822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OopAkcDkQe50"
      },
      "source": [
        "Next, let's determine if ask posts or show posts receive more comments on average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hpk5sBeQe52",
        "outputId": "cf5a82ee-2165-499f-ae7d-b8d567bb570f"
      },
      "source": [
        "total_ask_comments = 0\n",
        "\n",
        "for row in ask_posts:\n",
        "    total_ask_comments +=  int(row[4])\n",
        "    \n",
        "avg_ask_comments = total_ask_comments / len (ask_posts)\n",
        "\n",
        "total_show_comments = 0\n",
        "\n",
        "for row in show_posts:\n",
        "    total_show_comments +=  int(row[4])\n",
        "    \n",
        "avg_show_comments = total_show_comments / len (show_posts)\n",
        "\n",
        "print('Average number of Ask HN comments:',avg_ask_comments)\n",
        "print('Average number of Show HN comments:',avg_show_comments)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average number of Ask HN comments: 10.393478498741656\n",
            "Average number of Show HN comments: 4.886099625910612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXs1YRLXQe55"
      },
      "source": [
        "## Reformatting and Analyzing the Data\n",
        "\n",
        "It's clear that, on average, ask posts receive more comments than show posts. Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
        "\n",
        "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
        "\n",
        "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
        "2. Calculate the average number of comments ask posts receive by hour created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPZCP3SeQe57"
      },
      "source": [
        "We'll use the datetime module to work with the data in the created_at column to calculate the amount of ask posts and comments by hour created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNCDpDr3Qe58",
        "outputId": "4f3ad5ff-cbd5-4294-f00a-19ef6516aada"
      },
      "source": [
        "import datetime as dt\n",
        "\n",
        "result_list = []\n",
        "\n",
        "for row in ask_posts:\n",
        "    result_list.append ( [ row[6] , int(row[4]) ] )\n",
        "    \n",
        "counts_by_hour = {}\n",
        "comments_by_hour = {}\n",
        "\n",
        "for row in result_list:\n",
        "    time_created = dt.datetime.strptime(row[0],'%m/%d/%Y %H:%M')\n",
        "    hour = time_created.hour\n",
        "    \n",
        "    if hour not in counts_by_hour:\n",
        "        counts_by_hour[hour] = 1\n",
        "        comments_by_hour[hour] = row[1]\n",
        "    else:\n",
        "        counts_by_hour[hour] += 1\n",
        "        comments_by_hour[hour] += row[1]\n",
        "\n",
        "print('The number of ask posts created during each hour of the day:')\n",
        "print(counts_by_hour)\n",
        "print('\\n')\n",
        "print('The corresponding number of comments ask posts created at each hour received:')\n",
        "print(comments_by_hour)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of ask posts created during each hour of the day:\n",
            "{2: 269, 1: 282, 22: 383, 21: 518, 19: 552, 17: 587, 15: 646, 14: 513, 13: 444, 11: 312, 10: 282, 9: 222, 7: 226, 3: 271, 23: 343, 20: 510, 16: 579, 8: 257, 0: 301, 18: 614, 12: 342, 4: 243, 6: 234, 5: 209}\n",
            "\n",
            "\n",
            "The corresponding number of comments ask posts created at each hour received:\n",
            "{2: 2996, 1: 2089, 22: 3372, 21: 4500, 19: 3954, 17: 5547, 15: 18525, 14: 4972, 13: 7245, 11: 2797, 10: 3013, 9: 1477, 7: 1585, 3: 2154, 23: 2297, 20: 4462, 16: 4466, 8: 2362, 0: 2277, 18: 4877, 12: 4234, 4: 2360, 6: 1587, 5: 1838}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-4Y6a1SQe59"
      },
      "source": [
        "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day by creating a list of lists containing the hours during which posts were created and the average number of comments those posts received."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmnleCWsQe5-",
        "outputId": "5e82355d-211c-4b90-a7eb-5a8bdb67e48b"
      },
      "source": [
        "avg_by_hour = []\n",
        "\n",
        "for hour in counts_by_hour:\n",
        "    no_of_posts = counts_by_hour[hour]\n",
        "    no_of_comments = comments_by_hour[hour]\n",
        "    avg_no_comments = comments_by_hour[hour] / counts_by_hour[hour] \n",
        "    avg_by_hour.append([hour,avg_no_comments])\n",
        "    \n",
        "print(avg_by_hour)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2, 11.137546468401487], [1, 7.407801418439717], [22, 8.804177545691905], [21, 8.687258687258687], [19, 7.163043478260869], [17, 9.449744463373083], [15, 28.676470588235293], [14, 9.692007797270955], [13, 16.31756756756757], [11, 8.96474358974359], [10, 10.684397163120567], [9, 6.653153153153153], [7, 7.013274336283186], [3, 7.948339483394834], [23, 6.696793002915452], [20, 8.749019607843136], [16, 7.713298791018998], [8, 9.190661478599221], [0, 7.5647840531561465], [18, 7.94299674267101], [12, 12.380116959064328], [4, 9.7119341563786], [6, 6.782051282051282], [5, 8.794258373205741]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcSI9yoRQe6A"
      },
      "source": [
        "Now let's sort the above data in descending order of average number of comments for easy analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiOpW-E5Qe6C",
        "outputId": "f23a4c0e-1a79-4188-bc06-4805d6755a49"
      },
      "source": [
        "swap_avg_by_hour = []\n",
        "\n",
        "for value in avg_by_hour:\n",
        "    swap_avg_by_hour.append([value[1],value[0]])\n",
        "    \n",
        "sorted_swap = sorted(swap_avg_by_hour,reverse = True)\n",
        "\n",
        "print('Top 5 Hours for Ask Posts Comments')\n",
        "print('\\n')\n",
        "\n",
        "for row in sorted_swap:\n",
        "    template = '{time}:00: {num:.2f} average comments per post.'\n",
        "    print(template.format(time = row[1] , num = row[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 Hours for Ask Posts Comments\n",
            "\n",
            "\n",
            "15:00: 28.68 average comments per post.\n",
            "13:00: 16.32 average comments per post.\n",
            "12:00: 12.38 average comments per post.\n",
            "2:00: 11.14 average comments per post.\n",
            "10:00: 10.68 average comments per post.\n",
            "4:00: 9.71 average comments per post.\n",
            "14:00: 9.69 average comments per post.\n",
            "17:00: 9.45 average comments per post.\n",
            "8:00: 9.19 average comments per post.\n",
            "11:00: 8.96 average comments per post.\n",
            "22:00: 8.80 average comments per post.\n",
            "5:00: 8.79 average comments per post.\n",
            "20:00: 8.75 average comments per post.\n",
            "21:00: 8.69 average comments per post.\n",
            "3:00: 7.95 average comments per post.\n",
            "18:00: 7.94 average comments per post.\n",
            "16:00: 7.71 average comments per post.\n",
            "0:00: 7.56 average comments per post.\n",
            "1:00: 7.41 average comments per post.\n",
            "19:00: 7.16 average comments per post.\n",
            "7:00: 7.01 average comments per post.\n",
            "6:00: 6.78 average comments per post.\n",
            "23:00: 6.70 average comments per post.\n",
            "9:00: 6.65 average comments per post.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLy61Ou7Qe6E"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "- The Ask HN posts has Higher Average number of comments than the Show HN posts.\n",
        "- 3 pm GMT has the highest average number of comments."
      ]
    }
  ]
}